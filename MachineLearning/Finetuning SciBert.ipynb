{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1325,
     "status": "ok",
     "timestamp": 1648996987478,
     "user": {
      "displayName": "‡∏Å‡∏§‡∏ï‡∏¥‡∏ô ‡∏ä‡∏≤‡∏ï‡∏£‡∏µ‡∏ô‡∏±‡∏ô‡∏ó‡πå",
      "userId": "09907642380438869594"
     },
     "user_tz": -420
    },
    "id": "MuW-jgbVR0kZ"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 GPU(s) available.\n",
      "Device name: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU for now since all GPUs are full.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(\"Using CPU for now since all GPUs are full.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1648997015323,
     "user": {
      "displayName": "‡∏Å‡∏§‡∏ï‡∏¥‡∏ô ‡∏ä‡∏≤‡∏ï‡∏£‡∏µ‡∏ô‡∏±‡∏ô‡∏ó‡πå",
      "userId": "09907642380438869594"
     },
     "user_tz": -420
    },
    "id": "DGeZBqt2R3oh",
    "outputId": "5fbf65d2-4d81-45de-a0a0-0b83990dbeb1"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Set your base path\n",
    "base_path = Path(\"//data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/acl-arc\")\n",
    "\n",
    "# ‚úÖ Define label mapping\n",
    "label_map = {\n",
    "    0: \"background\",\n",
    "    1: \"uses\",\n",
    "    2: \"compares\",\n",
    "    3: \"motivation\",\n",
    "    4: \"continuation\",\n",
    "    5: \"future\"\n",
    "}\n",
    "\n",
    "# ‚úÖ Generic loader function\n",
    "def load_acl_arc_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path, on_bad_lines='skip', engine='python')\n",
    "\n",
    "    # Map labels from int to string\n",
    "    df[\"label\"] = df[\"intent\"].map(label_map)\n",
    "    df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "    X = df[\"cleaned_cite_text\"].astype(str).tolist()\n",
    "    y = df[\"label\"].tolist()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 506, Val: 34, Test: 41\n",
      "Sample label distribution (train): background      260\n",
      "uses             95\n",
      "compares         91\n",
      "continuation     23\n",
      "motivation       19\n",
      "future           18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, y_train = load_acl_arc_dataset(base_path / \"train_30_percent.csv\")\n",
    "X_val, y_val     = load_acl_arc_dataset(base_path / \"val_30_percent.csv\")\n",
    "X_test, y_test   = load_acl_arc_dataset(base_path / \"test_30_percent.csv\")\n",
    "\n",
    "# ‚úÖ Sanity check\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "print(\"Sample label distribution (train):\", pd.Series(y_train).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 811, Val: 174, Test: 174\n",
      "Train label distribution:\n",
      " intent\n",
      "0    417\n",
      "1    152\n",
      "2    146\n",
      "4     38\n",
      "3     29\n",
      "5     29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"#Load 30 % data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and combine the existing 30% datasets\n",
    "df_train = pd.read_csv(base_path / \"train_30_percent.csv\")\n",
    "df_val   = pd.read_csv(base_path / \"val_30_percent.csv\")\n",
    "df_test  = pd.read_csv(base_path / \"test_30_percent.csv\")\n",
    "\n",
    "# Combine all into one for stratified resplit\n",
    "df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "# Stratified split (70% train, 15% val, 15% test)\n",
    "X = df['text']\n",
    "y = df['intent']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test     = train_test_split(X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# ‚úÖ Optional: print for sanity\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "print(\"Sample label distribution (train):\")\n",
    "print(pd.Series(y_train).value_counts())\"\"\"\n",
    "\n",
    "#Load all data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----------- PATHS -----------\n",
    "data_dir = \"/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/acl-arc\"\n",
    "train_files = [\"train_10_percent.csv\", \"train_20_percent.csv\", \"train_30_percent.csv\"]\n",
    "val_files = [\"val_10_percent.csv\", \"val_20_percent.csv\", \"val_30_percent.csv\"]\n",
    "test_files = [\"test_10_percent.csv\", \"test_20_percent.csv\", \"test_30_percent.csv\"]\n",
    "\n",
    "# ----------- LOAD & COMBINE ALL CSVs -----------\n",
    "df_all = pd.concat(\n",
    "    [pd.read_csv(f\"{data_dir}/{f}\") for f in train_files + val_files + test_files],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# ----------- CLEAN TEXT & LABELS -----------\n",
    "X = df_all[\"cleaned_cite_text\"].astype(str)\n",
    "y = df_all[\"intent\"].astype(int)\n",
    "\n",
    "# ----------- STRATIFIED SPLIT: 70% train, 15% val, 15% test -----------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test     = train_test_split(X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# ----------- OPTIONAL: SANITY CHECK -----------\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "print(\"Train label distribution:\\n\", pd.Series(y_train).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "4154a003c626419b9c47a540e53fa428",
      "a8cc0af7284048548b56503d8f16139a",
      "f46c913c776841a8a3be19681986ce1a",
      "bd4178909db141819c80c6ee46ade5a8",
      "845d4da555684b0f96a6dd20d6ef57fa",
      "70cba6820a9e4e22ad87e251f5857801",
      "60b38f7133864f049bff92787313367f",
      "471aaa34c8b341189bbc206315edefbe",
      "1c61ec5d5a7b4259b450dfec9cb5a3ff",
      "4c5dd318ba8e4d5d8ebf2f1bef650efa",
      "96f1bc563b044f3b85933aee03d61598",
      "eb6b8611e956446391b278e4cacb22f8",
      "4a704fde880e4e119dd60c8f7c13b737",
      "633006ea85464d818db0614bdf863dcd",
      "f8940321d3d740b6a74a3c7e1ce2a55b",
      "59856599c9b64d6293963962306c48bb",
      "9b447b71e1eb4a65b30858bdd7cd4c6e",
      "b22ab15795ca4d5d9c6abab7bd163cd6",
      "c300b2baaaba46299461339ac05915e4",
      "ad4280a9f38343a59cb2947155cebca8",
      "d966efc185484fff80234a605bd86518",
      "dc23c978b66b4c8dbf49451a279b0d33"
     ]
    },
    "executionInfo": {
     "elapsed": 1809,
     "status": "ok",
     "timestamp": 1648997053305,
     "user": {
      "displayName": "‡∏Å‡∏§‡∏ï‡∏¥‡∏ô ‡∏ä‡∏≤‡∏ï‡∏£‡∏µ‡∏ô‡∏±‡∏ô‡∏ó‡πå",
      "userId": "09907642380438869594"
     },
     "user_tz": -420
    },
    "id": "0D5X1EWaSJyx",
    "outputId": "7092aede-ceaf-428c-8551-ffbe2ce38fc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anpa439f/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and add special token\n",
    "tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\", do_lower_case=True)\n",
    "tokenizer.add_tokens(['<cite>'])\n",
    "\n",
    "MAX_LEN = 256\n",
    "\n",
    "def tokenize_fast(text_list):\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "        text_list,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_tensors='pt'  # PyTorch tensors directly\n",
    "    )\n",
    "    return encoded['input_ids'], encoded['attention_mask'], encoded['token_type_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing datasets...\")\n",
    "\n",
    "train_inputs, train_masks, train_token_type = tokenize_fast(X_train)\n",
    "val_inputs, val_masks, val_token_type = tokenize_fast(X_val)\n",
    "test_inputs, test_masks, test_token_type = tokenize_fast(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = torch.tensor(list(y_train))\n",
    "y_val_encoded   = torch.tensor(list(y_val))\n",
    "y_test_encoded  = torch.tensor(list(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Train labels: {0, 1, 2, 3, 4, 5}\n",
      "Val labels: {0, 1, 2, 3, 4, 5}\n",
      "Test labels: {0, 1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "\n",
    "print(\"Train labels:\", set(y_train))\n",
    "print(\"Val labels:\", set(y_val))\n",
    "print(\"Test labels:\", set(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1648997116755,
     "user": {
      "displayName": "‡∏Å‡∏§‡∏ï‡∏¥‡∏ô ‡∏ä‡∏≤‡∏ï‡∏£‡∏µ‡∏ô‡∏±‡∏ô‡∏ó‡πå",
      "userId": "09907642380438869594"
     },
     "user_tz": -420
    },
    "id": "eg-qFHd_R4BQ",
    "outputId": "c0079277-938b-4476-ca62-408ec89ef997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [0.00239808 0.00657895 0.00684932 0.03448276 0.02631579 0.03448276]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Get class counts from encoded labels\n",
    "label_counts = Counter(y_train_encoded.tolist())\n",
    "num_classes = len(label_counts)\n",
    "\n",
    "# Inverse frequency weighting\n",
    "class_freq = np.array([label_counts[i] for i in range(num_classes)])\n",
    "class_weights = 1. / class_freq\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1648997120156,
     "user": {
      "displayName": "‡∏Å‡∏§‡∏ï‡∏¥‡∏ô ‡∏ä‡∏≤‡∏ï‡∏£‡∏µ‡∏ô‡∏±‡∏ô‡∏ó‡πå",
      "userId": "09907642380438869594"
     },
     "user_tz": -420
    },
    "id": "BglGw1T7R4D5",
    "outputId": "09688531-abc8-4b63-b39d-4d0ab882caf5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample weight vector shape: torch.Size([811])\n"
     ]
    }
   ],
   "source": [
    "# Map each training example to its corresponding class weight\n",
    "samples_weight = np.array([class_weights[label.item()] for label in y_train_encoded])\n",
    "samples_weight = torch.tensor(samples_weight, dtype=torch.float)\n",
    "\n",
    "print(\"Sample weight vector shape:\", samples_weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Wrap each dataset with its input + attention + token type + label\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, train_token_type, y_train_encoded)\n",
    "val_dataset   = TensorDataset(val_inputs, val_masks, val_token_type, y_val_encoded)\n",
    "test_dataset  = TensorDataset(test_inputs, test_masks, test_token_type, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Balanced sampler for training\n",
    "train_sampler = WeightedRandomSampler(weights=samples_weight, num_samples=len(samples_weight), replacement=True)\n",
    "\n",
    "# Sequential sampler for val/test (no randomness)\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "\n",
    "# DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "val_dataloader   = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch_size)\n",
    "test_dataloader  = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 26\n",
      "Example batch input shape: torch.Size([32, 256])\n",
      "Example labels: tensor([1, 0, 0, 1, 1, 4, 1, 1, 5, 0, 2, 2, 2, 3, 1, 4, 4, 2, 1, 2, 1, 5, 1, 0,\n",
      "        4, 5, 5, 2, 3, 4, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train batches:\", len(train_dataloader))\n",
    "example = next(iter(train_dataloader))\n",
    "print(\"Example batch input shape:\", example[0].shape)\n",
    "print(\"Example labels:\", example[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 31091. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "/home/anpa439f/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def initialize_model(epochs=10):\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"allenai/scibert_scivocab_uncased\",\n",
    "        num_labels=6,  # ‚ö†Ô∏è You have 6 labels\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    return model, optimizer, scheduler\n",
    "\n",
    "model, optimizer, scheduler = initialize_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper to calculate accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1)\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs=4, patience=2):\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n======== Epoch {epoch+1} / {epochs} ========\")\n",
    "\n",
    "        # ---------- Training ----------\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_steps = 0\n",
    "\n",
    "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            b_input_ids, b_input_mask, b_token_type_ids, b_labels = [t.to(device) for t in batch]\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=b_input_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                token_type_ids=b_token_type_ids,\n",
    "                labels=b_labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_steps += 1\n",
    "\n",
    "        avg_train_loss = total_loss / train_steps\n",
    "        print(f\"\\n‚úÖ Average training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # ---------- Validation ----------\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "            b_input_ids, b_input_mask, b_token_type_ids, b_labels = [t.to(device) for t in batch]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(\n",
    "                    input_ids=b_input_ids,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    token_type_ids=b_token_type_ids,\n",
    "                    labels=b_labels\n",
    "                )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            val_accuracy += flat_accuracy(logits, label_ids)\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        avg_val_loss = val_loss / nb_eval_steps\n",
    "        avg_val_accuracy = val_accuracy / nb_eval_steps\n",
    "\n",
    "        print(f\"‚úÖ Validation loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"‚úÖ Validation accuracy: {avg_val_accuracy:.4f}\")\n",
    "        # Log history\n",
    "        history.append({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "            \"val_accuracy\": avg_val_accuracy\n",
    "        })\n",
    "\n",
    "        # ---------- Early stopping and saving best model ----------\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            counter = 0\n",
    "            output_dir = \"scibert_6label_model_60_data\"\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            model.save_pretrained(output_dir)\n",
    "            tokenizer.save_pretrained(output_dir)\n",
    "            print(\"üíæ Saved new best model.\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # Save training log\n",
    "    pd.DataFrame(history).to_csv(\"training_log.csv\", index=False)\n",
    "    print(\"üìù Training log saved to training_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [13:18<00:00, 30.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 1.2555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:49<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation loss: 1.2549\n",
      "‚úÖ Validation accuracy: 0.5938\n",
      "üíæ Saved new best model.\n",
      "\n",
      "======== Epoch 2 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [13:32<00:00, 31.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 0.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:48<00:00,  8.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation loss: 1.0072\n",
      "‚úÖ Validation accuracy: 0.6607\n",
      "üíæ Saved new best model.\n",
      "\n",
      "======== Epoch 3 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [14:26<00:00, 33.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 0.6801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:48<00:00,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation loss: 0.8546\n",
      "‚úÖ Validation accuracy: 0.7195\n",
      "üíæ Saved new best model.\n",
      "\n",
      "======== Epoch 4 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [15:14<00:00, 35.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 0.4996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:55<00:00,  9.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation loss: 0.7590\n",
      "‚úÖ Validation accuracy: 0.7679\n",
      "üíæ Saved new best model.\n",
      "\n",
      "======== Epoch 5 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [15:46<00:00, 36.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 0.4087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:54<00:00,  9.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation loss: 0.6587\n",
      "‚úÖ Validation accuracy: 0.7768\n",
      "üíæ Saved new best model.\n",
      "\n",
      "======== Epoch 6 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [15:05<00:00, 34.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 0.3389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:58<00:00,  9.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation loss: 0.5816\n",
      "‚úÖ Validation accuracy: 0.8028\n",
      "üíæ Saved new best model.\n",
      "\n",
      "======== Epoch 7 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [13:23<00:00, 30.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 0.2776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:42<00:00,  7.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation loss: 0.5704\n",
      "‚úÖ Validation accuracy: 0.8185\n",
      "üíæ Saved new best model.\n",
      "\n",
      "======== Epoch 8 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [13:13<00:00, 30.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 0.2678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:55<00:00,  9.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation loss: 0.5481\n",
      "‚úÖ Validation accuracy: 0.7976\n",
      "üíæ Saved new best model.\n",
      "\n",
      "======== Epoch 9 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [14:24<00:00, 33.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 0.2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:49<00:00,  8.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation loss: 0.5416\n",
      "‚úÖ Validation accuracy: 0.7976\n",
      "üíæ Saved new best model.\n",
      "\n",
      "======== Epoch 10 / 10 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [12:55<00:00, 29.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Average training loss: 0.2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:25<00:25,  8.39s/it]"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('scibert_6label_model_combined_data/tokenizer_config.json',\n",
       " 'scibert_6label_model_combined_data/special_tokens_map.json',\n",
       " 'scibert_6label_model_combined_data/vocab.txt',\n",
       " 'scibert_6label_model_combined_data/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.save_pretrained(\"scibert_6label_model_30_data\")\n",
    "tokenizer.save_pretrained(\"scibert_6label_model_30_data\")\"\"\"\n",
    "\n",
    "model.save_pretrained(\"scibert_6label_model_combined_data\")\n",
    "tokenizer.save_pretrained(\"scibert_6label_model_combined_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting Epoch 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [17:33<00:00, 40.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Epoch 10 Training Loss: 0.2247\n",
      "\n",
      "üß™ Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:52<00:00,  8.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 10 Validation Loss: 0.5126\n",
      "‚úÖ Epoch 10 Validation Accuracy: 0.8653\n",
      "\n",
      "üöÄ Starting Epoch 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [16:16<00:00, 37.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Epoch 11 Training Loss: 0.1422\n",
      "\n",
      "üß™ Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:52<00:00,  8.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 11 Validation Loss: 0.4634\n",
      "‚úÖ Epoch 11 Validation Accuracy: 0.8326\n",
      "\n",
      "üöÄ Starting Epoch 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [16:03<00:00, 37.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Epoch 12 Training Loss: 0.1117\n",
      "\n",
      "üß™ Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:54<00:00,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 12 Validation Loss: 0.4519\n",
      "‚úÖ Epoch 12 Validation Accuracy: 0.8497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Continue 3 more epochs\n",
    "# Load saved model and tokenizer\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"scibert_6label_model_60_data\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"scibert_6label_model_60_data\")\n",
    "model.to(device)\n",
    "\n",
    "# Reinitialize optimizer and scheduler\n",
    "epochs_to_run = 3\n",
    "start_epoch = 10  # We continue from epoch 10\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "total_steps = len(train_dataloader) * epochs_to_run\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, start_epoch + epochs_to_run):\n",
    "    print(f\"\\nüöÄ Starting Epoch {epoch}...\\n\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        b_input_ids, b_input_mask, b_token_type_ids, b_labels = [t.to(device) for t in batch]\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            token_type_ids=b_token_type_ids,\n",
    "            labels=b_labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"\\n‚úÖ Epoch {epoch} Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    print(\"\\nüß™ Running validation...\")\n",
    "    model.eval()\n",
    "    val_loss, val_accuracy, steps = 0, 0, 0\n",
    "\n",
    "    for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "        b_input_ids, b_input_mask, b_token_type_ids, b_labels = [t.to(device) for t in batch]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=b_input_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                token_type_ids=b_token_type_ids,\n",
    "                labels=b_labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "        labels = b_labels.cpu().numpy()\n",
    "        val_accuracy += np.sum(preds == labels) / len(labels)\n",
    "        steps += 1\n",
    "\n",
    "    print(f\"‚úÖ Epoch {epoch} Validation Loss: {val_loss/steps:.4f}\")\n",
    "    print(f\"‚úÖ Epoch {epoch} Validation Accuracy: {val_accuracy/steps:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31091, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"scibert_6label_model_combined_data\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"scibert_6label_model_combined_data\")\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"background\",\n",
    "    1: \"uses\",\n",
    "    2: \"compares\",\n",
    "    3: \"continuation\",\n",
    "    4: \"motivation\",\n",
    "    5: \"future\"\n",
    "}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"scibert_6label_model_combined_data\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"scibert_6label_model_combined_data\")\n",
    "\n",
    "# Manually set correct label mapping\n",
    "model.config.id2label = {\n",
    "    0: \"background\",\n",
    "    1: \"uses\",\n",
    "    2: \"compares\",\n",
    "    3: \"continuation\",\n",
    "    4: \"motivation\",\n",
    "    5: \"future\"\n",
    "}\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def predict_citation_function(text):\n",
    "    model.eval()\n",
    "    encoded = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=256)\n",
    "    encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoded).logits\n",
    "    pred = torch.argmax(logits, dim=1).item()\n",
    "    return id2label[pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uses\n",
      "background\n",
      "continuation\n",
      "background\n",
      "background\n",
      "continuation\n",
      "continuation\n",
      "continuation\n",
      "uses\n",
      "compares\n",
      "continuation\n",
      "background\n",
      "background\n",
      "future\n",
      "future\n"
     ]
    }
   ],
   "source": [
    "print(predict_citation_function(\"We use the dataset proposed by Zhang et al. (2019).\"))\n",
    "# Expected: uses\n",
    "\n",
    "print(predict_citation_function(\"Previous work has shown that attention improves performance (Bahdanau et al., 2014).\"))\n",
    "# Expected: background\n",
    "\n",
    "print(predict_citation_function(\"Unlike Smith et al. (2018), our method does not require pretraining.\"))\n",
    "# Expected: compares\n",
    "\n",
    "print(predict_citation_function(\"Neural networks have been widely used for text classification since the work of Kim (2014).\"))\n",
    "# Expected: background\n",
    "\n",
    "print(predict_citation_function(\"Attention mechanisms were first introduced by Bahdanau et al. (2014) for machine translation.\"))\n",
    "# Expected: background\n",
    "\n",
    "print(predict_citation_function(\"We implement our model using the HuggingFace Transformers library (Wolf et al., 2020).\"))\n",
    "# Expected: uses\n",
    "\n",
    "print(predict_citation_function(\"Our results are evaluated using the same metrics as defined in (Lin, 2004).\"))\n",
    "# Expected: uses\n",
    "\n",
    "print(predict_citation_function(\"In contrast to Lee et al. (2019), our model does not rely on handcrafted features.\"))\n",
    "# Expected: compares\n",
    "\n",
    "print(predict_citation_function(\"Unlike BERT-based models (Devlin et al., 2019), our system uses no pretraining.\"))\n",
    "# Expected: compares\n",
    "\n",
    "print(predict_citation_function(\"This builds on the findings of Xu et al. (2021), who first applied contrastive loss in this context.\"))\n",
    "# Expected: continuation\n",
    "\n",
    "print(predict_citation_function(\"Our work extends the dialogue framework proposed in (Ritter et al., 2011).\"))\n",
    "# Expected: continuation\n",
    "\n",
    "print(predict_citation_function(\"While recent models achieve high accuracy, they require large computational resources (Brown et al., 2020).\"))\n",
    "# Expected: motivation\n",
    "\n",
    "print(predict_citation_function(\"Despite promising results from prior work (Yin et al., 2017), scalability remains an issue.\"))\n",
    "# Expected: motivation\n",
    "print(predict_citation_function(\"Future work could explore integrating multimodal inputs as done in (Zellers et al., 2021).\"))\n",
    "# Expected: future\n",
    "\n",
    "print(predict_citation_function(\"We plan to investigate the use of reinforcement learning for this task, inspired by (Silver et al., 2016).\"))\n",
    "# Expected: future\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anpa439f/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting Epoch 13...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [15:26<00:00, 35.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Epoch 13 Training Loss: 0.0988\n",
      "\n",
      "üß™ Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:52<00:00,  8.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 13 Validation Loss: 0.4677\n",
      "‚úÖ Epoch 13 Validation Accuracy: 0.8549\n",
      "\n",
      "üöÄ Starting Epoch 14...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|‚ñç         | 1/26 [00:42<17:37, 42.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning SciBert.ipynb Cell 28\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m‚úÖ Epoch \u001b[39m\u001b[39m{\u001b[39;00mep\u001b[39m}\u001b[39;00m\u001b[39m Validation Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mval_accuracy\u001b[39m/\u001b[39msteps\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m# Call the function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m resume_n_epochs(model, train_dataloader, val_dataloader, optimizer, scheduler, start_epoch\u001b[39m=\u001b[39;49m\u001b[39m13\u001b[39;49m, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "\u001b[1;32m/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning SciBert.ipynb Cell 28\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m b_input_ids, b_input_mask, b_token_type_ids, b_labels \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     input_ids\u001b[39m=\u001b[39;49mb_input_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mb_input_mask,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mb_token_type_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     labels\u001b[39m=\u001b[39;49mb_labels\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin2.alpha.hpc.tu-dresden.de/data/horse/ws/anpa439f-Function_Retrieval_Citation/Research_Project/classification_data/Finetuning%20SciBert.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1562\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1563\u001b[0m     input_ids,\n\u001b[1;32m   1564\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1565\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1566\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1567\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1568\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1569\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1570\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1571\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1572\u001b[0m )\n\u001b[1;32m   1574\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1576\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[0;32m-> 1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1023\u001b[0m     embedding_output,\n\u001b[1;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1025\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1026\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1027\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1028\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1029\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1030\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1031\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1033\u001b[0m )\n\u001b[1;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:612\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    603\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    604\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    605\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    611\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    613\u001b[0m         hidden_states,\n\u001b[1;32m    614\u001b[0m         attention_mask,\n\u001b[1;32m    615\u001b[0m         layer_head_mask,\n\u001b[1;32m    616\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    617\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    618\u001b[0m         past_key_value,\n\u001b[1;32m    619\u001b[0m         output_attentions,\n\u001b[1;32m    620\u001b[0m     )\n\u001b[1;32m    622\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    498\u001b[0m         hidden_states,\n\u001b[1;32m    499\u001b[0m         attention_mask,\n\u001b[1;32m    500\u001b[0m         head_mask,\n\u001b[1;32m    501\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    502\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:436\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    427\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[0;32m--> 436\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(self_outputs[\u001b[39m0\u001b[39;49m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:388\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    386\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    387\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 388\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mLayerNorm(hidden_states \u001b[39m+\u001b[39;49m input_tensor)\n\u001b[1;32m    389\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlayer_norm(\n\u001b[1;32m    191\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, normalized_shape, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mlayer_norm(\u001b[39minput\u001b[39;49m, normalized_shape, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load model and tokenizer from the epoch 12 checkpoint\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"scibert_6label_model_ep12\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"scibert_6label_model_ep12\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# Reinitialize optimizer and scheduler for 2 more epochs\n",
    "epochs = 2\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Training for 2 more epochs\n",
    "def resume_n_epochs(model, train_dataloader, val_dataloader, optimizer, scheduler, start_epoch, n_epochs):\n",
    "    for ep in range(start_epoch, start_epoch + n_epochs):\n",
    "        print(f\"\\nüöÄ Starting Epoch {ep}...\\n\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            b_input_ids, b_input_mask, b_token_type_ids, b_labels = [t.to(device) for t in batch]\n",
    "\n",
    "            model.zero_grad()\n",
    "            outputs = model(\n",
    "                input_ids=b_input_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                token_type_ids=b_token_type_ids,\n",
    "                labels=b_labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"\\n‚úÖ Epoch {ep} Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        print(\"\\nüß™ Running validation...\")\n",
    "        model.eval()\n",
    "        val_loss, val_accuracy, steps = 0, 0, 0\n",
    "\n",
    "        for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "            b_input_ids, b_input_mask, b_token_type_ids, b_labels = [t.to(device) for t in batch]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(\n",
    "                    input_ids=b_input_ids,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    token_type_ids=b_token_type_ids,\n",
    "                    labels=b_labels\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "            labels = b_labels.cpu().numpy()\n",
    "            val_accuracy += np.sum(preds == labels) / len(labels)\n",
    "            steps += 1\n",
    "\n",
    "        print(f\"‚úÖ Epoch {ep} Validation Loss: {val_loss/steps:.4f}\")\n",
    "        print(f\"‚úÖ Epoch {ep} Validation Accuracy: {val_accuracy/steps:.4f}\")\n",
    "\n",
    "# Call the function\n",
    "resume_n_epochs(model, train_dataloader, val_dataloader, optimizer, scheduler, start_epoch=13, n_epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('scibert_6label_model_ep12/tokenizer_config.json',\n",
       " 'scibert_6label_model_ep12/special_tokens_map.json',\n",
       " 'scibert_6label_model_ep12/vocab.txt',\n",
       " 'scibert_6label_model_ep12/added_tokens.json',\n",
       " 'scibert_6label_model_ep12/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"scibert_6label_model_ep12\")\n",
    "tokenizer.save_pretrained(\"scibert_6label_model_ep12\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"scibert_6label_model_ep12\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"scibert_6label_model_ep12\")\n",
    "\n",
    "# Manually set correct label mapping\n",
    "model.config.id2label = {\n",
    "    0: \"background\",\n",
    "    1: \"uses\",\n",
    "    2: \"compares\",\n",
    "    3: \"continuation\",\n",
    "    4: \"motivation\",\n",
    "    5: \"future\"\n",
    "}\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Classification Report on Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background       0.92      0.92      0.92        90\n",
      "        uses       0.88      0.88      0.88        33\n",
      "    compares       0.72      0.74      0.73        31\n",
      "continuation       1.00      0.67      0.80         6\n",
      "  motivation       0.56      0.62      0.59         8\n",
      "      future       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.86       174\n",
      "   macro avg       0.85      0.81      0.82       174\n",
      "weighted avg       0.87      0.86      0.86       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    b_input_ids, b_input_mask, b_token_type_ids, b_labels = [t.to(device) for t in batch]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            token_type_ids=b_token_type_ids\n",
    "        )\n",
    "\n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    label_ids = b_labels.cpu().numpy()\n",
    "\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(label_ids)\n",
    "\n",
    "# Map label IDs to names\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "target_names = [id2label[i] for i in range(len(label2id))]\n",
    "\n",
    "# Print classification report\n",
    "print(\"üìä Classification Report on Test Set\")\n",
    "print(classification_report(all_labels, all_preds, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=target_names, yticklabels=target_names, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix on Test Set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def print_softmax_for_compares(X_test, y_test, tokenizer, model, device):\n",
    "    print(\"üß™ Confidence scores for `compares` test examples:\\n\")\n",
    "    compares_label_id = label2id[\"compares\"]\n",
    "\n",
    "    for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
    "        if true_label != \"compares\":\n",
    "            continue\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=256\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probs = F.softmax(logits, dim=1).squeeze().cpu().numpy()\n",
    "            pred_id = int(torch.argmax(logits, dim=1).cpu().item())\n",
    "\n",
    "        sorted_probs = sorted([(i, p) for i, p in enumerate(probs)], key=lambda x: x[1], reverse=True)\n",
    "        top_2 = sorted_probs[:2]\n",
    "\n",
    "        print(f\"üìù Example {i+1}:\")\n",
    "        print(f\"Text: {text[:150]}{'...' if len(text) > 150 else ''}\")\n",
    "        print(f\"True label: compares\")\n",
    "        print(f\"Predicted label: {id2label[pred_id]}\")\n",
    "        print(\"Confidence scores:\")\n",
    "        for idx, score in enumerate(probs):\n",
    "            print(f\"  {id2label[idx]:>12}: {score:.4f}\")\n",
    "        print(f\"üî• Top 2 predictions: {[(id2label[i], f'{p:.2f}') for i, p in top_2]}\")\n",
    "        print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def collect_softmax_for_all(X_test, y_test, tokenizer, model, device):\n",
    "    results = []\n",
    "\n",
    "    for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probs = F.softmax(logits, dim=1).squeeze().cpu().numpy()\n",
    "            pred_id = int(torch.argmax(logits, dim=1).cpu().item())\n",
    "\n",
    "        sorted_probs = sorted([(j, p) for j, p in enumerate(probs)], key=lambda x: x[1], reverse=True)\n",
    "        top_2 = [(id2label[j], float(f\"{p:.4f}\")) for j, p in sorted_probs[:2]]\n",
    "\n",
    "        result = {\n",
    "            \"example_index\": i + 1,\n",
    "            \"text\": text,\n",
    "            \"true_label\": id2label[true_label],\n",
    "            \"predicted_label\": id2label[pred_id],\n",
    "            \"top_2_predictions\": top_2\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Example</th>\n",
       "      <th>True Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Top 1</th>\n",
       "      <th>Top 2</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>background</td>\n",
       "      <td>background</td>\n",
       "      <td>background (0.58)</td>\n",
       "      <td>compares (0.22)</td>\n",
       "      <td>√¢¬Ä¬¢ Learnability ( Zernik and Dyer 1987 ) √¢¬Ä¬¢ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>continuation</td>\n",
       "      <td>continuation</td>\n",
       "      <td>continuation (0.31)</td>\n",
       "      <td>uses (0.20)</td>\n",
       "      <td>Previously ( @@CITATION ) , we assessed the im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>uses</td>\n",
       "      <td>uses</td>\n",
       "      <td>uses (0.60)</td>\n",
       "      <td>background (0.14)</td>\n",
       "      <td>To build the above s2t system , we first use t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>background</td>\n",
       "      <td>background</td>\n",
       "      <td>background (0.58)</td>\n",
       "      <td>compares (0.16)</td>\n",
       "      <td>This system has been successfully tested with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>uses</td>\n",
       "      <td>background</td>\n",
       "      <td>background (0.41)</td>\n",
       "      <td>uses (0.28)</td>\n",
       "      <td>A statistical technique which has recently bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>170</td>\n",
       "      <td>background</td>\n",
       "      <td>compares</td>\n",
       "      <td>compares (0.39)</td>\n",
       "      <td>background (0.31)</td>\n",
       "      <td>This is the strongest version of the sorites p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>171</td>\n",
       "      <td>compares</td>\n",
       "      <td>compares</td>\n",
       "      <td>compares (0.54)</td>\n",
       "      <td>background (0.23)</td>\n",
       "      <td>This was done because purely unsupervised tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>172</td>\n",
       "      <td>background</td>\n",
       "      <td>background</td>\n",
       "      <td>background (0.66)</td>\n",
       "      <td>compares (0.15)</td>\n",
       "      <td>Discriminative approaches ( especially SVMs ) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>173</td>\n",
       "      <td>uses</td>\n",
       "      <td>uses</td>\n",
       "      <td>uses (0.55)</td>\n",
       "      <td>background (0.15)</td>\n",
       "      <td>Other molecular biology databases We also incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>174</td>\n",
       "      <td>background</td>\n",
       "      <td>continuation</td>\n",
       "      <td>continuation (0.54)</td>\n",
       "      <td>uses (0.14)</td>\n",
       "      <td>We have presented an ensemble approach to word...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Example    True Label Predicted Label                Top 1  \\\n",
       "0          1    background      background    background (0.58)   \n",
       "1          2  continuation    continuation  continuation (0.31)   \n",
       "2          3          uses            uses          uses (0.60)   \n",
       "3          4    background      background    background (0.58)   \n",
       "4          5          uses      background    background (0.41)   \n",
       "..       ...           ...             ...                  ...   \n",
       "169      170    background        compares      compares (0.39)   \n",
       "170      171      compares        compares      compares (0.54)   \n",
       "171      172    background      background    background (0.66)   \n",
       "172      173          uses            uses          uses (0.55)   \n",
       "173      174    background    continuation  continuation (0.54)   \n",
       "\n",
       "                 Top 2                                               Text  \n",
       "0      compares (0.22)  √¢¬Ä¬¢ Learnability ( Zernik and Dyer 1987 ) √¢¬Ä¬¢ ...  \n",
       "1          uses (0.20)  Previously ( @@CITATION ) , we assessed the im...  \n",
       "2    background (0.14)  To build the above s2t system , we first use t...  \n",
       "3      compares (0.16)  This system has been successfully tested with ...  \n",
       "4          uses (0.28)  A statistical technique which has recently bec...  \n",
       "..                 ...                                                ...  \n",
       "169  background (0.31)  This is the strongest version of the sorites p...  \n",
       "170  background (0.23)  This was done because purely unsupervised tech...  \n",
       "171    compares (0.15)  Discriminative approaches ( especially SVMs ) ...  \n",
       "172  background (0.15)  Other molecular biology databases We also incl...  \n",
       "173        uses (0.14)  We have presented an ensemble approach to word...  \n",
       "\n",
       "[174 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_list = collect_softmax_for_all(X_test, y_test, tokenizer, model, device)\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"Example\": r[\"example_index\"],\n",
    "        \"True Label\": r[\"true_label\"],\n",
    "        \"Predicted Label\": r[\"predicted_label\"],\n",
    "        \"Top 1\": f\"{r['top_2_predictions'][0][0]} ({r['top_2_predictions'][0][1]:.2f})\",\n",
    "        \"Top 2\": f\"{r['top_2_predictions'][1][0]} ({r['top_2_predictions'][1][1]:.2f})\",\n",
    "        \"Text\": r[\"text\"][:100] + (\"...\" if len(r[\"text\"]) > 100 else \"\")\n",
    "    }\n",
    "    for r in results_list\n",
    "])\n",
    "\n",
    "# Display the table in Jupyter Notebook\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test_predictions.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMz3d6BlE2wNPNgKrsRO+Nl",
   "mount_file_id": "1oBKroMlV0FIVnFHPmOwAgIbf-iRAps_O",
   "name": "AlgoCite - Finetuning SciBert Full Version.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1c61ec5d5a7b4259b450dfec9cb5a3ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e9c9d8d05fb4ddda00b0f51dd41fb90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33dec13ebefa47f998fa2b531795433b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b8ddfffbeb0747fbac66d26ea7d2f711",
       "IPY_MODEL_4d146986793e4910b0718324bb8937ae",
       "IPY_MODEL_a2af500222f841cb9bd59ff62b220427"
      ],
      "layout": "IPY_MODEL_fc82743aef59456bac1d910c8253ce18"
     }
    },
    "4154a003c626419b9c47a540e53fa428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8cc0af7284048548b56503d8f16139a",
       "IPY_MODEL_f46c913c776841a8a3be19681986ce1a",
       "IPY_MODEL_bd4178909db141819c80c6ee46ade5a8"
      ],
      "layout": "IPY_MODEL_845d4da555684b0f96a6dd20d6ef57fa"
     }
    },
    "471aaa34c8b341189bbc206315edefbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a704fde880e4e119dd60c8f7c13b737": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b447b71e1eb4a65b30858bdd7cd4c6e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b22ab15795ca4d5d9c6abab7bd163cd6",
      "value": "Downloading: 100%"
     }
    },
    "4c5dd318ba8e4d5d8ebf2f1bef650efa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d146986793e4910b0718324bb8937ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7761a9de35a542049e7b1dc599b51472",
      "max": 442221694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e9c9d8d05fb4ddda00b0f51dd41fb90",
      "value": 442221694
     }
    },
    "59856599c9b64d6293963962306c48bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60b38f7133864f049bff92787313367f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "633006ea85464d818db0614bdf863dcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c300b2baaaba46299461339ac05915e4",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad4280a9f38343a59cb2947155cebca8",
      "value": 385
     }
    },
    "70cba6820a9e4e22ad87e251f5857801": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7761a9de35a542049e7b1dc599b51472": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "845d4da555684b0f96a6dd20d6ef57fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96f1bc563b044f3b85933aee03d61598": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b447b71e1eb4a65b30858bdd7cd4c6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2af500222f841cb9bd59ff62b220427": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d67d7508fdea472fa95c7f557b2b467b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e183d30fc70e49cc8fab688b58df5a51",
      "value": " 422M/422M [00:14&lt;00:00, 31.9MB/s]"
     }
    },
    "a8cc0af7284048548b56503d8f16139a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70cba6820a9e4e22ad87e251f5857801",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_60b38f7133864f049bff92787313367f",
      "value": "Downloading: 100%"
     }
    },
    "ad4280a9f38343a59cb2947155cebca8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b22ab15795ca4d5d9c6abab7bd163cd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8ddfffbeb0747fbac66d26ea7d2f711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e93034f06e2240169162d3aeb08b6a78",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f7b9b8db78a74a6b9e420c6099330650",
      "value": "Downloading: 100%"
     }
    },
    "bd4178909db141819c80c6ee46ade5a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c5dd318ba8e4d5d8ebf2f1bef650efa",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_96f1bc563b044f3b85933aee03d61598",
      "value": " 223k/223k [00:00&lt;00:00, 1.23MB/s]"
     }
    },
    "c300b2baaaba46299461339ac05915e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d67d7508fdea472fa95c7f557b2b467b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d966efc185484fff80234a605bd86518": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc23c978b66b4c8dbf49451a279b0d33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e183d30fc70e49cc8fab688b58df5a51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e93034f06e2240169162d3aeb08b6a78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb6b8611e956446391b278e4cacb22f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4a704fde880e4e119dd60c8f7c13b737",
       "IPY_MODEL_633006ea85464d818db0614bdf863dcd",
       "IPY_MODEL_f8940321d3d740b6a74a3c7e1ce2a55b"
      ],
      "layout": "IPY_MODEL_59856599c9b64d6293963962306c48bb"
     }
    },
    "f46c913c776841a8a3be19681986ce1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_471aaa34c8b341189bbc206315edefbe",
      "max": 227845,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c61ec5d5a7b4259b450dfec9cb5a3ff",
      "value": 227845
     }
    },
    "f7b9b8db78a74a6b9e420c6099330650": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8940321d3d740b6a74a3c7e1ce2a55b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d966efc185484fff80234a605bd86518",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_dc23c978b66b4c8dbf49451a279b0d33",
      "value": " 385/385 [00:00&lt;00:00, 9.36kB/s]"
     }
    },
    "fc82743aef59456bac1d910c8253ce18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
