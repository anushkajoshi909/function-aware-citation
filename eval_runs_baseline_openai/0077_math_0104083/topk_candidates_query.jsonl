{"rank": 0, "score": 0.9067298173904419, "paper_id": "math/0104083", "title": "Sparsity vs. Statistical Independence in Adaptive Signal\n  Representations: A Case Study of the Spike Process", "abstract": "Finding a basis/coordinate system that can efficiently represent an input\ndata stream by viewing them as realizations of a stochastic process is of\ntremendous importance in many fields including data compression and\ncomputational neuroscience. Two popular measures of such efficiency of a basis\nare sparsity (measured by the expected $\\ell^p$ norm, $0 < p \\leq 1$) and\nstatistical independence (measured by the mutual information). Gaining deeper\nunderstanding of their intricate relationship, however, remains elusive.\nTherefore, we chose to study a simple synthetic stochastic process called the\nspike process, which puts a unit impulse at a random location in an\n$n$-dimensional vector for each realization. For this process, we obtained the\nfollowing results: 1) The standard basis is the best both in terms of sparsity\nand statistical independence if $n \\geq 5$ and the search of basis is\nrestricted within all possible orthonormal bases in $R^n$; 2) If we extend our\nbasis search in all possible invertible linear transformations in $R^n$, then\nthe best basis in statistical independence differs from the one in sparsity; 3)\nIn either of the above, the best basis in statistical independence is not\nunique, and there even exist those which make the inputs completely dense; 4)\nThere is no linear invertible transformation that achieves the true statistical\nindependence for $n > 2$.", "abstract_full": "Finding a basis/coordinate system that can efficiently represent an input\ndata stream by viewing them as realizations of a stochastic process is of\ntremendous importance in many fields including data compression and\ncomputational neuroscience. Two popular measures of such efficiency of a basis\nare sparsity (measured by the expected $\\ell^p$ norm, $0 < p \\leq 1$) and\nstatistical independence (measured by the mutual information). Gaining deeper\nunderstanding of their intricate relationship, however, remains elusive.\nTherefore, we chose to study a simple synthetic stochastic process called the\nspike process, which puts a unit impulse at a random location in an\n$n$-dimensional vector for each realization. For this process, we obtained the\nfollowing results: 1) The standard basis is the best both in terms of sparsity\nand statistical independence if $n \\geq 5$ and the search of basis is\nrestricted within all possible orthonormal bases in $R^n$; 2) If we extend our\nbasis search in all possible invertible linear transformations in $R^n$, then\nthe best basis in statistical independence differs from the one in sparsity; 3)\nIn either of the above, the best basis in statistical independence is not\nunique, and there even exist those which make the inputs completely dense; 4)\nThere is no linear invertible transformation that achieves the true statistical\nindependence for $n > 2$.", "authors": "Bertrand Benichou, Naoki Saito", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
{"rank": 1, "score": 0.8463074564933777, "paper_id": "quant-ph/0104061", "title": "Efficient Implementation and the Product State Representation of Numbers", "abstract": "The relation between the requirement of efficient implementability and the\nproduct state representation of numbers is examined. Numbers are defined to be\nany model of the axioms of number theory or arithmetic. Efficient\nimplementability (EI) means that the basic arithmetic operations are physically\nimplementable and the space-time and thermodynamic resources needed to carry\nout the implementations are polynomial in the range of numbers considered.\nDifferent models of numbers are described to show the independence of both EI\nand the product state representation from the axioms. The relation between EI\nand the product state representation is examined. It is seen that the condition\nof a product state representation does not imply EI. Arguments used to refute\nthe converse implication, EI implies a product state representation, seem\nreasonable; but they are not conclusive. Thus this implication remains an open\nquestion.", "abstract_full": "The relation between the requirement of efficient implementability and the\nproduct state representation of numbers is examined. Numbers are defined to be\nany model of the axioms of number theory or arithmetic. Efficient\nimplementability (EI) means that the basic arithmetic operations are physically\nimplementable and the space-time and thermodynamic resources needed to carry\nout the implementations are polynomial in the range of numbers considered.\nDifferent models of numbers are described to show the independence of both EI\nand the product state representation from the axioms. The relation between EI\nand the product state representation is examined. It is seen that the condition\nof a product state representation does not imply EI. Arguments used to refute\nthe converse implication, EI implies a product state representation, seem\nreasonable; but they are not conclusive. Thus this implication remains an open\nquestion.", "authors": "Paul Benioff", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
{"rank": 2, "score": 0.8398021459579468, "paper_id": "physics/0101065", "title": "Relation of uncertainty for time", "abstract": "We introduce two time: deterministic Newton time-stream t and stochastic\ntime-epoch $\\tau$. The relation of uncertainty for time-epoch of physical\nevents $\\Delta\\tau\\Delta D \\geq c_1,\\eqno(*)$ where $c_1=const$, is proved. The\nfunction $D(t)= - c_1\\frac{d}{dt}\\ln f_\\tau (t),$ characterizes {\\it velocity\nof disorganization} of the event-phenomena; $f_\\tau (t)$ is density of\nprobability of time-epoch $\\tau$.\n  The relation (*) is verified not by means of experiment that is traditional\nfor physics, but with the help of the reference to datas of historical science.", "abstract_full": "We introduce two time: deterministic Newton time-stream t and stochastic\ntime-epoch $\\tau$. The relation of uncertainty for time-epoch of physical\nevents $\\Delta\\tau\\Delta D \\geq c_1,\\eqno(*)$ where $c_1=const$, is proved. The\nfunction $D(t)= - c_1\\frac{d}{dt}\\ln f_\\tau (t),$ characterizes {\\it velocity\nof disorganization} of the event-phenomena; $f_\\tau (t)$ is density of\nprobability of time-epoch $\\tau$.\n  The relation (*) is verified not by means of experiment that is traditional\nfor physics, but with the help of the reference to datas of historical science.", "authors": "Alexander K. Guts", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
{"rank": 3, "score": 0.8384681344032288, "paper_id": "cond-mat/0103246", "title": "Signatures of Randomness in Quantum Chaos", "abstract": "We investigate toy dynamical models of energy-level repulsion in quantum\neigenvalue sequences. We focus on parametric (with respect to a running\ncoupling or \"complexity\" parameter) stochastic processes that are capable of\nrelaxing towards a stationary regime (e. g. equilibrium, invariant asymptotic\nmeasure). In view of ergodic property, that makes them appropriate for the\nstudy of short-range fluctuations in any disordered, randomly-looking spectral\nsequence (as exemplified e. g. by empirical nearest-neighbor spacings\nhistograms of various quantum systems). The pertinent Markov diffusion-type\nprocesses (with values in the space of spacings) share a general form of\nforward drifts $b(x) = {{N-1}\\over {2x}} - x$, where $x>0$ stands for the\nspacing value. Here $N = 2,3,5$ correspond to the familiar (generic)\nrandom-matrix theory inspired cases, based on the exploitation of the Wigner\nsurmise (usually regarded as an approximate formula). N=4 corresponds to the\n(non-generic) non-Hermitian Ginibre ensemble. The result appears to be exact in\nthe context of $2\\times 2$ random matrices and indicates a potential validity\nof other non-generic $N>5$ level repulsion laws.", "abstract_full": "We investigate toy dynamical models of energy-level repulsion in quantum\neigenvalue sequences. We focus on parametric (with respect to a running\ncoupling or \"complexity\" parameter) stochastic processes that are capable of\nrelaxing towards a stationary regime (e. g. equilibrium, invariant asymptotic\nmeasure). In view of ergodic property, that makes them appropriate for the\nstudy of short-range fluctuations in any disordered, randomly-looking spectral\nsequence (as exemplified e. g. by empirical nearest-neighbor spacings\nhistograms of various quantum systems). The pertinent Markov diffusion-type\nprocesses (with values in the space of spacings) share a general form of\nforward drifts $b(x) = {{N-1}\\over {2x}} - x$, where $x>0$ stands for the\nspacing value. Here $N = 2,3,5$ correspond to the familiar (generic)\nrandom-matrix theory inspired cases, based on the exploitation of the Wigner\nsurmise (usually regarded as an approximate formula). N=4 corresponds to the\n(non-generic) non-Hermitian Ginibre ensemble. The result appears to be exact in\nthe context of $2\\times 2$ random matrices and indicates a potential validity\nof other non-generic $N>5$ level repulsion laws.", "authors": "Piotr Garbaczewski", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
{"rank": 4, "score": 0.8383243680000305, "paper_id": "nucl-th/0103026", "title": "The effect of gluon depletion on J/psi suppression in pA and AA\n  collisions", "abstract": "The enhanced suppression of $J/\\psi$ production at large $x_F$ in $pA$\ncollisions is studied in the framework of gluon depletion at large $x_1$. The\nnonperturbative process that modifies the gluon distribution as the gluons\npropagate in nuclear matter is described by an evolution equation with a kernal\nto be determined by phenomenology. With nuclear shadowing and anti-shadowing\ntaken into account, the effect on the gluon distribution is shown to be a\ndepletion in excess of 40% at $x_1 \\approx 0.8$ for $A > 100$. There is a small\namount of enhancement of the gluon distribution at small $x_1$, but it does not\nlead to any contradiction with the existing data on $J/\\psi$ suppression in the\ncentral region. Extentions to $\\psi^{\\prime}$ suppression and $AB$ collisions\nare also investigated in the framework of gluon redistribution.", "abstract_full": "The enhanced suppression of $J/\\psi$ production at large $x_F$ in $pA$\ncollisions is studied in the framework of gluon depletion at large $x_1$. The\nnonperturbative process that modifies the gluon distribution as the gluons\npropagate in nuclear matter is described by an evolution equation with a kernal\nto be determined by phenomenology. With nuclear shadowing and anti-shadowing\ntaken into account, the effect on the gluon distribution is shown to be a\ndepletion in excess of 40% at $x_1 \\approx 0.8$ for $A > 100$. There is a small\namount of enhancement of the gluon distribution at small $x_1$, but it does not\nlead to any contradiction with the existing data on $J/\\psi$ suppression in the\ncentral region. Extentions to $\\psi^{\\prime}$ suppression and $AB$ collisions\nare also investigated in the framework of gluon redistribution.", "authors": "Rudolph C. Hwa, Jan Pisut, Neva Pisutova", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
{"rank": 5, "score": 0.8378589153289795, "paper_id": "math/0101037", "title": "Reconstruction from projections using dynamics: Non-Stochastic Case", "abstract": "The problem of determining three-dimensional density fields from single\ntwo-dimensional projections is hopelessly underdetermined without additional\nassumptions. While parameterized inversions are typically used to solve this\nproblem, we present theoretical results along a different route to the\nelimination of indeterminacy. Suppose that we have a series of N radiographs\nmeasuring X-ray or proton attenuation through an evolving object at a sequence\nof times. Suppose also that we know the deterministic dynamical laws governing\nthe evolution of the object we are probing with radiography. The these laws can\nbe used to combine the radiographs into one \"super\"-measurement which can then\nbe inverted to the object sequence. Now suppose the objects are points in $R^n$\nand the radiographs are points in $R^d$. It would be expected that the best we\ncould do would be to get invertability when N = $\\lceil n/d \\rceil$. The worst\ncase is that we never get invertability. We look at both cases carefully for\nlinear dynamics. We show that dynamical laws giving this optimally short\ninvertibility time are generic. We then illustrate with numerical examples and\npresent a conjecture for the nonlinear case.", "abstract_full": "The problem of determining three-dimensional density fields from single\ntwo-dimensional projections is hopelessly underdetermined without additional\nassumptions. While parameterized inversions are typically used to solve this\nproblem, we present theoretical results along a different route to the\nelimination of indeterminacy. Suppose that we have a series of N radiographs\nmeasuring X-ray or proton attenuation through an evolving object at a sequence\nof times. Suppose also that we know the deterministic dynamical laws governing\nthe evolution of the object we are probing with radiography. The these laws can\nbe used to combine the radiographs into one \"super\"-measurement which can then\nbe inverted to the object sequence. Now suppose the objects are points in $R^n$\nand the radiographs are points in $R^d$. It would be expected that the best we\ncould do would be to get invertability when N = $\\lceil n/d \\rceil$. The worst\ncase is that we never get invertability. We look at both cases carefully for\nlinear dynamics. We show that dynamical laws giving this optimally short\ninvertibility time are generic. We then illustrate with numerical examples and\npresent a conjecture for the nonlinear case.", "authors": "Kevin R. Vixie, Gary L. Sandine", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
{"rank": 6, "score": 0.8345920443534851, "paper_id": "math/0103104", "title": "Detection of spatial pattern through independence of thinned processes", "abstract": "Let N, N' and N'' be point processes such that N' is obtained from N by\nhomogeneous independent thinning and N''= N- N'. We give a new elementary proof\nthat N' and N'' are independent if and only if N is a Poisson point process. We\npresent some applications of this result to test if a homogeneous point process\nis a Poisson point process.", "abstract_full": "Let N, N' and N'' be point processes such that N' is obtained from N by\nhomogeneous independent thinning and N''= N- N'. We give a new elementary proof\nthat N' and N'' are independent if and only if N is a Poisson point process. We\npresent some applications of this result to test if a homogeneous point process\nis a Poisson point process.", "authors": "Renato M. Assuncao, Pablo A. Ferrari", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
{"rank": 7, "score": 0.8340882062911987, "paper_id": "gr-qc/0101051", "title": "Detecting a non-Gaussian stochastic background of gravitational\n  radiation", "abstract": "We derive a detection method for a stochastic background of gravitational\nwaves produced by events where the ratio of the average time between events to\nthe average duration of an event is large. Such a signal would sound something\nlike popcorn popping. Our derivation is based on the somewhat unrealistic\nassumption that the duration of an event is smaller than the detector time\nresolution.", "abstract_full": "We derive a detection method for a stochastic background of gravitational\nwaves produced by events where the ratio of the average time between events to\nthe average duration of an event is large. Such a signal would sound something\nlike popcorn popping. Our derivation is based on the somewhat unrealistic\nassumption that the duration of an event is smaller than the detector time\nresolution.", "authors": "Steve Drasco, Eanna E. Flanagan", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
{"rank": 8, "score": 0.8339685201644897, "paper_id": "cond-mat/0102181", "title": "Regularities Unseen, Randomness Observed: Levels of Entropy Convergence", "abstract": "We study how the Shannon entropy of sequences produced by an information\nsource converges to the source's entropy rate. We synthesize several\nphenomenological approaches to applying information theoretic measures of\nrandomness and memory to stochastic and deterministic processes by using\nsuccessive derivatives of the Shannon entropy growth curve. This leads, in\nturn, to natural measures of apparent memory stored in a source and the amounts\nof information that must be extracted from observations of a source in order\nfor it to be optimally predicted and for an observer to synchronize to it. One\nconsequence of ignoring these structural properties is that the missed\nregularities are converted to apparent randomness. We demonstrate that this\nproblem arises particularly for small data sets; e.g., in settings where one\nhas access only to short measurement sequences.", "abstract_full": "We study how the Shannon entropy of sequences produced by an information\nsource converges to the source's entropy rate. We synthesize several\nphenomenological approaches to applying information theoretic measures of\nrandomness and memory to stochastic and deterministic processes by using\nsuccessive derivatives of the Shannon entropy growth curve. This leads, in\nturn, to natural measures of apparent memory stored in a source and the amounts\nof information that must be extracted from observations of a source in order\nfor it to be optimally predicted and for an observer to synchronize to it. One\nconsequence of ignoring these structural properties is that the missed\nregularities are converted to apparent randomness. We demonstrate that this\nproblem arises particularly for small data sets; e.g., in settings where one\nhas access only to short measurement sequences.", "authors": "James P. Crutchfield, David P. Feldman", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
{"rank": 9, "score": 0.8336610794067383, "paper_id": "math/0103033", "title": "Filtered stochastic calculus", "abstract": "By introducing a color filtration to the multiplicity space, we extend the\nquantum Ito calculus on multiple symmetric Fock space to the framework of\nfiltered adapted biprocesses. In this new notion of adaptedness,``classical''\ntime filtration makes the integrands similar to adapted processes, whereas\n``quantum'' color filtration produces their deviations from adaptedness. An\nimportant feature of this calculus, which we call filtered stochastic calculus,\nis that it provides an explicit interpolation between the main types of\ncalculi, regardless of the type of independence, including freeness, Boolean\nindependence (more generally, m-freeness) as well as tensor independence.\nMoreover, it shows how boson calculus is ``deformed'' by other noncommutative\nnotions of independence.", "abstract_full": "By introducing a color filtration to the multiplicity space, we extend the\nquantum Ito calculus on multiple symmetric Fock space to the framework of\nfiltered adapted biprocesses. In this new notion of adaptedness,``classical''\ntime filtration makes the integrands similar to adapted processes, whereas\n``quantum'' color filtration produces their deviations from adaptedness. An\nimportant feature of this calculus, which we call filtered stochastic calculus,\nis that it provides an explicit interpolation between the main types of\ncalculi, regardless of the type of independence, including freeness, Boolean\nindependence (more generally, m-freeness) as well as tensor independence.\nMoreover, it shows how boson calculus is ``deformed'' by other noncommutative\nnotions of independence.", "authors": "Romuald Lenczewski", "year": "2001", "retrieved_at": "2025-10-26T16:50:20"}
